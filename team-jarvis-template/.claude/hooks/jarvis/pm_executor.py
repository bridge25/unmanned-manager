#!/usr/bin/env python3
"""
JARVIS PM Executor - /pm ìŠ¬ë˜ì‹œ ì»¤ë§¨ë“œ ì‹¤í–‰ê¸°
=============================================
í”„ë¡œì íŠ¸ë³„ ì‘ì—…ì„ ìµœì ì˜ LLMìœ¼ë¡œ ìœ„ì„

ì‘ì„±ì¼: 2025-12-18
ì—…ë°ì´íŠ¸: 2025-12-25 (tmux ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í†µí•©)
ë°©ì‹: tmux ì„¸ì…˜ ì§ì ‘ ì£¼ì… + LLM ë¼ìš°íŒ…
"""
import json
import subprocess
import time
import uuid
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Tuple

# tmux ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì„í¬íŠ¸
try:
    from .tmux_orchestrator import TmuxOrchestrator, CommandResult
    TMUX_AVAILABLE = True
except ImportError:
    try:
        from tmux_orchestrator import TmuxOrchestrator, CommandResult
        TMUX_AVAILABLE = True
    except ImportError:
        TMUX_AVAILABLE = False
        TmuxOrchestrator = None
        CommandResult = None

# PM Cycle Recorder ì„í¬íŠ¸ (ìœ ì‚¬ ì¼€ì´ìŠ¤ ì œì•ˆìš©)
PM_CYCLE_RECORDER_AVAILABLE = False
try:
    import sys
    _pm_pipelines_path = Path(__file__).parent.parent.parent.parent / "jarvis" / "pipelines"
    if _pm_pipelines_path.exists() and str(_pm_pipelines_path) not in sys.path:
        sys.path.insert(0, str(_pm_pipelines_path))
    from pm_cycle_recorder import get_recorder, PMResolution
    PM_CYCLE_RECORDER_AVAILABLE = True
except ImportError:
    get_recorder = None
    PMResolution = None

# í”„ë¡œì íŠ¸ ë² ì´ìŠ¤ ê²½ë¡œ
PROJECTS_BASE = Path("/Volumes/d/users/tony/Desktop/projects")

# í”„ë¡œì íŠ¸ ë§¤í•‘ (ë³„ì¹­ â†’ ì‹¤ì œ í´ë”ëª…)
PROJECT_MAPPING = {
    # í•´ë™ê¸°íš
    "í•´ë™ê²€ë„": "order-automation-saas",
    "í•´ë™ê¸°íš": "order-automation-saas",
    "í•´ë™": "order-automation-saas",
    "haedong": "order-automation-saas",

    # Japan Sale
    "japan": "japan",
    "ì¼ë³¸": "japan",
    "japansale": "japan",

    # FlyMoney
    "flymoney": "flymoney",
    "fly": "flymoney",
    "í•­ê³µ": "flymoney",

    # DT-RAG
    "dt-rag": "dt-rag",
    "rag": "dt-rag",
    "dtrag": "dt-rag",

    # í¬ë¦½í† ë©˜í† 
    "í¬ë¦½í† ë©˜í† ": "premium-contents-scrraper",
    "ë©˜í† ": "premium-contents-scrraper",
    "í¬ë¦½í† ": "premium-contents-scrraper",
    "crypto": "premium-contents-scrraper",

    # ì‚¬ì£¼
    "ì‚¬ì£¼": "saju",
    "saju": "saju",

    # QR ì£¼ì°¨
    "qrì£¼ì°¨": "qr-parking-demo",
    "ì£¼ì°¨": "qr-parking-demo",
    "qrparking": "qr-parking-demo",
    "parking": "qr-parking-demo",

    # í”„ë ˆì  í† 
    "í”„ë ˆì  í† ": "daddy's-ppt",
    "prezento": "daddy's-ppt",
}

# LLM ì„ íƒ í‚¤ì›Œë“œ
LLM_KEYWORDS = {
    "codex": {
        "keywords": [
            "ë””ë²„ê¹…", "debug", "í…ŒìŠ¤íŠ¸", "test", "lint", "ë¹Œë“œ", "build",
            "ì ê²€", "ë¦¬ë·°", "review", "cicd", "ci/cd", "ë°°í¬", "deploy",
            "ë²„ê·¸", "bug", "ì—ëŸ¬", "error", "fix", "ìˆ˜ì •", "ì²´í¬", "check",
            "ì»¤ë²„ë¦¬ì§€", "coverage", "íƒ€ì…", "type", "ë³´ì•ˆ", "security"
        ],
        "confidence_boost": 0.2,
    },
    "gemini": {
        "keywords": [
            "ë¦¬ì„œì¹˜", "research", "ë¬¸ì„œ", "ì¡°ì‚¬", "ê²€ìƒ‰", "íƒìƒ‰",
            "ê¸´ë¬¸ì„œ", "ëŒ€ìš©ëŸ‰", "ë¶„ì„ë ˆí¬íŠ¸"
        ],
        "confidence_boost": 0.25,
    },
    "glm": {
        "keywords": [
            "ë²Œí¬", "bulk", "ëŒ€ëŸ‰", "ë³€í™˜", "transform", "ì¶”ì¶œ", "extract",
            "ê°„ë‹¨", "simple", "ë¹ ë¥´ê²Œ", "quick", "ìš”ì•½", "summary",
            "ë²ˆì—­", "translate", "í¬ë§·", "format"
        ],
        "confidence_boost": 0.2,
    },
    "glm-v": {
        "keywords": [
            "ì´ë¯¸ì§€", "image", "ìŠ¤í¬ë¦°ìƒ·", "screenshot", "ui", "ë””ìì¸",
            "design", "ì‹œê°", "visual", "ì˜ìƒ", "video", "ë©€í‹°ëª¨ë‹¬",
            "í™”ë©´", "ìº¡ì²˜", "ì‚¬ì§„", "ê·¸ë¦¼"
        ],
        "confidence_boost": 0.25,
    },
}

# í™•ì‹ ë„ ì„ê³„ê°’ (ì´ ì´ìƒì´ë©´ ìë™ ì„ íƒ, ë¯¸ë§Œì´ë©´ ì‚¬ìš©ì í™•ì¸)
CONFIDENCE_THRESHOLD = 0.75


@dataclass
class SimilarSuggestion:
    """ìœ ì‚¬ í•´ê²° ì‚¬ë¡€ ì œì•ˆ"""
    score: float  # 0.0 ~ 1.0
    project: str
    issue_title: str
    resolution_summary: str
    commit_hash: Optional[str] = None


@dataclass
class LLMSelection:
    """LLM ì„ íƒ ê²°ê³¼"""
    llm: str
    confidence: float
    reason: str
    matched_keywords: list[str]


@dataclass
class PMResult:
    """PM ì‹¤í–‰ ê²°ê³¼"""
    success: bool
    llm_used: str
    output: str
    duration: float
    project_path: str
    error: Optional[str] = None


def get_project_path(project_name: str) -> Optional[Path]:
    """í”„ë¡œì íŠ¸ëª…ìœ¼ë¡œ ì‹¤ì œ ê²½ë¡œ ì°¾ê¸°"""
    # ì •í™•í•œ ë§¤í•‘ ë¨¼ì €
    normalized = project_name.lower().strip()

    if normalized in PROJECT_MAPPING:
        path = PROJECTS_BASE / PROJECT_MAPPING[normalized]
        if path.exists():
            return path

    # ë¶€ë¶„ ë§¤ì¹­
    for alias, folder in PROJECT_MAPPING.items():
        if alias in normalized or normalized in alias:
            path = PROJECTS_BASE / folder
            if path.exists():
                return path

    # ì§ì ‘ í´ë”ëª…ìœ¼ë¡œ ì‹œë„
    direct_path = PROJECTS_BASE / project_name
    if direct_path.exists():
        return direct_path

    return None


def select_llm(instruction: str) -> LLMSelection:
    """ì§€ì‹œ ë‚´ìš© ë¶„ì„í•˜ì—¬ ìµœì  LLM ì„ íƒ"""
    instruction_lower = instruction.lower()

    scores = {"codex": 0.0, "gemini": 0.0, "glm": -100.0, "glm-v": -100.0, "claude": 0.3}  # claude ê¸°ë³¸ê°’, glm/glm-v ë¼ìš°íŒ… ì œì™¸
    matched = {"codex": [], "gemini": [], "glm": [], "glm-v": [], "claude": []}

    # í‚¤ì›Œë“œ ë§¤ì¹­
    for llm, config in LLM_KEYWORDS.items():
        for keyword in config["keywords"]:
            if keyword.lower() in instruction_lower:
                scores[llm] += config["confidence_boost"]
                matched[llm].append(keyword)

    # ìµœê³  ì ìˆ˜ LLM ì„ íƒ
    best_llm = max(scores, key=scores.get)
    best_score = scores[best_llm]

    # ì´ìœ  ìƒì„±
    if matched[best_llm]:
        reason = f"í‚¤ì›Œë“œ ë§¤ì¹­: {', '.join(matched[best_llm][:3])}"
    else:
        reason = "ê¸°ë³¸ ì„ íƒ (ë³µì¡í•œ íŒë‹¨ í•„ìš”)"

    return LLMSelection(
        llm=best_llm,
        confidence=min(best_score + 0.3, 1.0),  # ê¸°ë³¸ 0.3 + í‚¤ì›Œë“œ ì ìˆ˜
        reason=reason,
        matched_keywords=matched[best_llm]
    )


def needs_confirmation(selection: LLMSelection) -> bool:
    """ì‚¬ìš©ì í™•ì¸ì´ í•„ìš”í•œì§€ íŒë‹¨"""
    return selection.confidence < CONFIDENCE_THRESHOLD


def get_similar_suggestions(
    instruction: str,
    project: Optional[str] = None,
    limit: int = 3
) -> list[SimilarSuggestion]:
    """
    ì§€ì‹œ ë‚´ìš©ê³¼ ìœ ì‚¬í•œ í•´ê²° ì‚¬ë¡€ ê²€ìƒ‰

    Args:
        instruction: PM ì§€ì‹œ ë‚´ìš©
        project: í”„ë¡œì íŠ¸ëª… (ì„ íƒ, ìˆìœ¼ë©´ í•´ë‹¹ í”„ë¡œì íŠ¸ ìš°ì„ )
        limit: ë°˜í™˜í•  ìµœëŒ€ ê±´ìˆ˜

    Returns:
        SimilarSuggestion ë¦¬ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ë†’ì€ ìˆœ)
    """
    if not PM_CYCLE_RECORDER_AVAILABLE or get_recorder is None:
        return []

    try:
        recorder = get_recorder()
        results = recorder.search_similar(instruction, limit=limit + 2)

        suggestions = []
        for score, resolution in results:
            # ìœ ì‚¬ë„ 50% ì´ìƒë§Œ
            if score >= 0.5:
                # ê°™ì€ í”„ë¡œì íŠ¸ë©´ ì ìˆ˜ ë¶€ìŠ¤íŠ¸
                adjusted_score = score
                if project and resolution.project.lower() == project.lower():
                    adjusted_score = min(score + 0.1, 1.0)

                suggestions.append(SimilarSuggestion(
                    score=adjusted_score,
                    project=resolution.project,
                    issue_title=resolution.issue_title,
                    resolution_summary=resolution.resolution_summary,
                    commit_hash=resolution.commit_hash
                ))

        # ì ìˆ˜ìˆœ ì¬ì •ë ¬
        suggestions.sort(key=lambda x: x.score, reverse=True)
        return suggestions[:limit]

    except Exception:
        return []


def format_suggestions_context(suggestions: list[SimilarSuggestion]) -> str:
    """ìœ ì‚¬ ì¼€ì´ìŠ¤ ì œì•ˆì„ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ í¬ë§·"""
    if not suggestions:
        return ""

    lines = ["ğŸ’¡ **ìœ ì‚¬ í•´ê²° ì‚¬ë¡€ ë°œê²¬**"]

    for i, s in enumerate(suggestions, 1):
        score_pct = int(s.score * 100)
        lines.append(f"   {i}. [{score_pct}%] {s.project}: {s.issue_title}")
        lines.append(f"      â†’ {s.resolution_summary[:60]}...")
        if s.commit_hash:
            lines.append(f"      ğŸ”— `{s.commit_hash}`")

    lines.append("")
    lines.append("   ì°¸ê³ : `/pm:similar <í‚¤ì›Œë“œ>` ë¡œ ë” ê²€ìƒ‰ ê°€ëŠ¥")

    return "\n".join(lines)


def format_confirmation_question(selection: LLMSelection, instruction: str) -> dict:
    """AskUserQuestionìš© ì§ˆë¬¸ í¬ë§·"""
    llm_descriptions = {
        "codex": "ì½”ë“œ ì ê²€/ë””ë²„ê¹…/ë³´ì•ˆ",
        "gemini": "Gemini 3 Flash (2M ì»¨í…ìŠ¤íŠ¸)",
        "glm": "GLM-4.7 í…ìŠ¤íŠ¸ (ë²Œí¬/ìš”ì•½/ì½”ë”©)",
        "glm-v": "GLM-4.6V ë¹„ì „ (ì´ë¯¸ì§€/UI ë¶„ì„)",
        "claude": "ë³µì¡í•œ íŒë‹¨/ê°œë°œ"
    }

    options = []

    # ì¶”ì²œ LLM ë¨¼ì €
    desc = llm_descriptions.get(selection.llm, selection.llm)
    options.append({
        "label": f"{selection.llm.upper()} (ì¶”ì²œ)",
        "description": f"{desc} - {selection.reason}"
    })

    # ë‚˜ë¨¸ì§€ LLM (ì¤‘ìš”ë„ ìˆœ) - glm/glm-v ì œì™¸
    for llm in ["codex", "gemini", "claude"]:
        if llm != selection.llm and len(options) < 4:
            options.append({
                "label": llm.upper(),
                "description": llm_descriptions.get(llm, llm)
            })

    return {
        "question": f"'{instruction[:30]}...' ì‘ì—…ì— ì–´ë–¤ LLMì„ ì‚¬ìš©í• ê¹Œìš”?",
        "header": "LLM ì„ íƒ",
        "options": options[:4],  # ìµœëŒ€ 4ê°œ
        "multiSelect": False
    }


def run_with_codex(project_path: Path, instruction: str, timeout: int = 300) -> PMResult:
    """Codex CLIë¡œ ì‹¤í–‰"""
    start = time.time()
    session_id = f"jarvis-pm-{uuid.uuid4().hex[:8]}"

    try:
        # codex ëª…ë ¹ì–´ êµ¬ì„±
        cmd = [
            "codex", "exec",
            "--sandbox", "workspace-write",
            instruction
        ]

        result = subprocess.run(
            cmd,
            cwd=project_path,
            capture_output=True,
            text=True,
            timeout=timeout
        )

        duration = time.time() - start

        if result.returncode == 0:
            return PMResult(
                success=True,
                llm_used="codex",
                output=result.stdout,
                duration=duration,
                project_path=str(project_path)
            )
        else:
            return PMResult(
                success=False,
                llm_used="codex",
                output=result.stdout,
                duration=duration,
                project_path=str(project_path),
                error=result.stderr or f"Exit code: {result.returncode}"
            )

    except subprocess.TimeoutExpired:
        return PMResult(
            success=False,
            llm_used="codex",
            output="",
            duration=timeout,
            project_path=str(project_path),
            error=f"Timeout after {timeout}s"
        )
    except Exception as e:
        return PMResult(
            success=False,
            llm_used="codex",
            output="",
            duration=time.time() - start,
            project_path=str(project_path),
            error=str(e)
        )


def run_with_gemini(project_path: Path, instruction: str, timeout: int = 180) -> PMResult:
    """Gemini CLIë¡œ ì‹¤í–‰"""
    start = time.time()

    try:
        cmd = ["gemini", "--yolo", instruction]

        result = subprocess.run(
            cmd,
            cwd=project_path,
            capture_output=True,
            text=True,
            timeout=timeout
        )

        duration = time.time() - start

        return PMResult(
            success=result.returncode == 0,
            llm_used="gemini",
            output=result.stdout,
            duration=duration,
            project_path=str(project_path),
            error=result.stderr if result.returncode != 0 else None
        )

    except subprocess.TimeoutExpired:
        return PMResult(
            success=False,
            llm_used="gemini",
            output="",
            duration=timeout,
            project_path=str(project_path),
            error=f"Timeout after {timeout}s"
        )
    except Exception as e:
        return PMResult(
            success=False,
            llm_used="gemini",
            output="",
            duration=time.time() - start,
            project_path=str(project_path),
            error=str(e)
        )


def run_with_glm(project_path: Path, instruction: str, timeout: int = 90) -> PMResult:
    """GLM-4.6 (í…ìŠ¤íŠ¸) HTTP APIë¡œ ì‹¤í–‰"""
    start = time.time()

    try:
        # GLMExecutor ì„í¬íŠ¸ ì‹œë„
        import sys
        jarvis_path = Path(__file__).parent.parent.parent.parent / "jarvis"
        if str(jarvis_path) not in sys.path:
            sys.path.insert(0, str(jarvis_path))

        from orchestrator.executors.glm_executor import GLMExecutor
        from orchestrator.executors.base import ExecutorContext

        executor = GLMExecutor(model="glm-4.7", timeout=timeout)
        context = ExecutorContext(
            task_id=f"pm-{uuid.uuid4().hex[:8]}",
            instruction=instruction,
            project=str(project_path.name),
            timeout=timeout,
            metadata={"project_path": str(project_path)}
        )

        result = executor.execute(context)
        duration = time.time() - start

        if result.success:
            output = result.output.get("agent_response", "") if isinstance(result.output, dict) else str(result.output)
            return PMResult(
                success=True,
                llm_used="glm-4.7",
                output=output,
                duration=duration,
                project_path=str(project_path)
            )
        else:
            return PMResult(
                success=False,
                llm_used="glm-4.7",
                output="",
                duration=duration,
                project_path=str(project_path),
                error=result.error
            )

    except ImportError as e:
        return PMResult(
            success=False,
            llm_used="glm-4.7",
            output="",
            duration=time.time() - start,
            project_path=str(project_path),
            error=f"GLMExecutor ì„í¬íŠ¸ ì‹¤íŒ¨: {e}"
        )
    except Exception as e:
        return PMResult(
            success=False,
            llm_used="glm-4.7",
            output="",
            duration=time.time() - start,
            project_path=str(project_path),
            error=str(e)
        )


def run_with_glm_vision(project_path: Path, instruction: str, image_path: str = None, timeout: int = 120) -> PMResult:
    """GLM-4.6V (ë¹„ì „) HTTP APIë¡œ ì‹¤í–‰"""
    start = time.time()

    try:
        import sys
        jarvis_path = Path(__file__).parent.parent.parent.parent / "jarvis"
        if str(jarvis_path) not in sys.path:
            sys.path.insert(0, str(jarvis_path))

        from orchestrator.executors.glm_executor import GLMExecutor
        from orchestrator.executors.base import ExecutorContext

        executor = GLMExecutor(vision_model="glm-4.6v", timeout=timeout)

        metadata = {"project_path": str(project_path)}
        if image_path:
            metadata["image_url"] = image_path

        context = ExecutorContext(
            task_id=f"pm-v-{uuid.uuid4().hex[:8]}",
            instruction=instruction,
            project=str(project_path.name),
            timeout=timeout,
            metadata=metadata
        )

        result = executor.execute(context)
        duration = time.time() - start

        if result.success:
            output = result.output.get("agent_response", "") if isinstance(result.output, dict) else str(result.output)
            return PMResult(
                success=True,
                llm_used="glm-4.6v",
                output=output,
                duration=duration,
                project_path=str(project_path)
            )
        else:
            return PMResult(
                success=False,
                llm_used="glm-4.6v",
                output="",
                duration=duration,
                project_path=str(project_path),
                error=result.error
            )

    except ImportError as e:
        return PMResult(
            success=False,
            llm_used="glm-4.6v",
            output="",
            duration=time.time() - start,
            project_path=str(project_path),
            error=f"GLMExecutor ì„í¬íŠ¸ ì‹¤íŒ¨: {e}"
        )
    except Exception as e:
        return PMResult(
            success=False,
            llm_used="glm-4.6v",
            output="",
            duration=time.time() - start,
            project_path=str(project_path),
            error=str(e)
        )


# =============================================================================
# tmux ê¸°ë°˜ ì‹¤í–‰ í•¨ìˆ˜ë“¤ (2025-12-25 ì¶”ê°€)
# =============================================================================

def run_with_tmux(
    project: str,
    instruction: str,
    wait_seconds: float = 30.0,
    use_claude: bool = True
) -> PMResult:
    """
    tmux ì„¸ì…˜ì— ëª…ë ¹/ì§€ì‹œ ì „ì†¡

    Args:
        project: í”„ë¡œì íŠ¸ëª…
        instruction: ì§€ì‹œ ë‚´ìš©
        wait_seconds: ê²°ê³¼ ëŒ€ê¸° ì‹œê°„
        use_claude: Trueë©´ Claudeì—ê²Œ ì§€ì‹œ, Falseë©´ ì‰˜ ëª…ë ¹

    Returns:
        PMResult
    """
    if not TMUX_AVAILABLE:
        return PMResult(
            success=False,
            llm_used="tmux",
            output="",
            duration=0,
            project_path="",
            error="tmux_orchestrator not available"
        )

    start = time.time()
    orch = TmuxOrchestrator()

    # ì„¸ì…˜ ì¡´ì¬ í™•ì¸, ì—†ìœ¼ë©´ ìƒì„±
    session_name = orch.get_session_name(project)
    if not session_name:
        return PMResult(
            success=False,
            llm_used="tmux",
            output="",
            duration=0,
            project_path="",
            error=f"Unknown project: {project}"
        )

    sessions = orch.list_sessions()
    if session_name not in sessions or not sessions[session_name]["exists"]:
        success, msg = orch.create_session(project)
        if not success:
            return PMResult(
                success=False,
                llm_used="tmux",
                output="",
                duration=time.time() - start,
                project_path="",
                error=f"Failed to create session: {msg}"
            )

    # ëª…ë ¹ ì „ì†¡
    if use_claude:
        result = orch.send_to_claude(project, instruction, wait_seconds)
    else:
        result = orch.send_command(project, instruction, wait_seconds)

    return PMResult(
        success=result.success,
        llm_used="tmux-claude" if use_claude else "tmux-shell",
        output=result.output,
        duration=result.duration,
        project_path=str(orch.sessions[session_name].project_path) if session_name in orch.sessions else "",
        error=result.error
    )


def run_with_tmux_dispatch(
    project: str,
    instruction: str,
    timeout: int = 300,
    wait_for_result: bool = True
) -> PMResult:
    """
    tmux ì„¸ì…˜ì— ì§€ì‹œ ì „ì†¡ (dispatch_task ì‚¬ìš©, íŒŒì¼ IPC ê²°ê³¼ ìˆ˜ì‹ )

    Args:
        project: í”„ë¡œì íŠ¸ëª…
        instruction: ì§€ì‹œ ë‚´ìš©
        timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        wait_for_result: ê²°ê³¼ ëŒ€ê¸° ì—¬ë¶€

    ì´ í•¨ìˆ˜ëŠ” tmux_orchestratorì˜ dispatch_taskë¥¼ ì‚¬ìš©í•˜ì—¬:
    1. ì§€ì‹œì— LLM ë¼ìš°íŒ… ê°•ì œ ëª…ë ¹ ìë™ ì¶”ê°€ (codex, gemini ë“±)
    2. ê²°ê³¼ë¥¼ íŒŒì¼ IPCë¡œ ìˆ˜ì‹ 
    """
    if not TMUX_AVAILABLE:
        return PMResult(
            success=False,
            llm_used="tmux",
            output="",
            duration=0,
            project_path="",
            error="tmux_orchestrator not available"
        )

    start = time.time()
    orch = TmuxOrchestrator()

    # ì„¸ì…˜ í™•ì¸/ìƒì„±
    session_name = orch.get_session_name(project)
    if not session_name:
        return PMResult(
            success=False,
            llm_used="tmux",
            output="",
            duration=0,
            project_path="",
            error=f"Unknown project: {project}"
        )

    sessions = orch.list_sessions()
    if session_name not in sessions or not sessions[session_name]["exists"]:
        success, msg = orch.create_session(project)
        if not success:
            return PMResult(
                success=False,
                llm_used="tmux",
                output="",
                duration=time.time() - start,
                project_path="",
                error=f"Failed to create session: {msg}"
            )

    # dispatch_taskë¡œ ì „ì†¡ (LLM ë¼ìš°íŒ… ê°•ì œ ìë™ ì ìš©ë¨)
    task_id, result_text = orch.dispatch_task(
        project=project,
        instruction=instruction,
        timeout=timeout,
        wait_for_result=wait_for_result
    )

    duration = time.time() - start
    project_path = str(orch.sessions[session_name].project_path) if session_name in orch.sessions else ""

    if task_id:
        return PMResult(
            success=result_text is not None,
            llm_used="tmux-claude",
            output=result_text or f"Task dispatched: {task_id} (async)",
            duration=duration,
            project_path=project_path,
            error=None if result_text else "No result received" if wait_for_result else None
        )
    else:
        return PMResult(
            success=False,
            llm_used="tmux-claude",
            output="",
            duration=duration,
            project_path=project_path,
            error="Failed to dispatch task"
        )


# =============================================================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# =============================================================================

def run_pm_task(
    project: str,
    instruction: str,
    llm_override: Optional[str] = None,
    use_tmux: bool = True  # ê¸°ë³¸ê°’: tmux ì‚¬ìš©
) -> Tuple[PMResult, LLMSelection]:
    """
    PM ì‘ì—… ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜

    Args:
        project: í”„ë¡œì íŠ¸ëª… ë˜ëŠ” ë³„ì¹­
        instruction: ì§€ì‹œ ë‚´ìš©
        llm_override: ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ LLM (ìˆìœ¼ë©´ ìë™ ì„ íƒ ë¬´ì‹œ)
        use_tmux: Trueë©´ tmux ì„¸ì…˜ ì‚¬ìš©, Falseë©´ subprocess ì‚¬ìš©

    Returns:
        (PMResult, LLMSelection) íŠœí”Œ
    """
    # 1. í”„ë¡œì íŠ¸ ê²½ë¡œ ì°¾ê¸°
    project_path = get_project_path(project)
    if not project_path:
        return PMResult(
            success=False,
            llm_used="none",
            output="",
            duration=0,
            project_path="",
            error=f"í”„ë¡œì íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project}"
        ), LLMSelection("none", 0, "í”„ë¡œì íŠ¸ ì—†ìŒ", [])

    # 2. LLM ì„ íƒ
    selection = select_llm(instruction)

    # ì‚¬ìš©ì ì§€ì •ì´ ìˆìœ¼ë©´ ì˜¤ë²„ë¼ì´ë“œ
    if llm_override:
        selection.llm = llm_override.lower()
        selection.confidence = 1.0
        selection.reason = "ì‚¬ìš©ì ì„ íƒ"

    # 3. ì„ íƒëœ LLMìœ¼ë¡œ ì‹¤í–‰
    if use_tmux and TMUX_AVAILABLE:
        # tmux ëª¨ë“œ: dispatch_task ì‚¬ìš© (LLM ë¼ìš°íŒ… ê°•ì œ ìë™ ì ìš©)
        # codex/gemini í‚¤ì›Œë“œê°€ ì§€ì‹œì— ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ CLI í˜¸ì¶œ ê°•ì œ ëª…ë ¹ ì¶”ê°€ë¨
        if selection.llm in ("codex", "gemini", "claude"):
            result = run_with_tmux_dispatch(project, instruction, timeout=300)
        else:
            # GLMì€ tmux ë¯¸ì§€ì›, subprocess í´ë°±
            if selection.llm == "glm":
                result = run_with_glm(project_path, instruction)
            elif selection.llm == "glm-v":
                result = run_with_glm_vision(project_path, instruction)
            else:
                result = run_with_tmux_dispatch(project, instruction, timeout=300)
    else:
        # subprocess ëª¨ë“œ (ë ˆê±°ì‹œ)
        if selection.llm == "codex":
            result = run_with_codex(project_path, instruction)
        elif selection.llm == "gemini":
            result = run_with_gemini(project_path, instruction)
        elif selection.llm == "glm":
            result = run_with_glm(project_path, instruction)
        elif selection.llm == "glm-v":
            result = run_with_glm_vision(project_path, instruction)
        else:
            # ClaudeëŠ” í˜„ì¬ ì„¸ì…˜ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì•ˆë‚´ë§Œ
            result = PMResult(
                success=True,
                llm_used="claude",
                output="ClaudeëŠ” í˜„ì¬ ì„¸ì…˜ì—ì„œ ì§ì ‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.",
                duration=0,
                project_path=str(project_path)
            )

    return result, selection


def format_result_report(
    result: PMResult,
    selection: LLMSelection,
    suggestions: Optional[list[SimilarSuggestion]] = None
) -> str:
    """ê²°ê³¼ë¥¼ ë³´ê³  í˜•ì‹ìœ¼ë¡œ í¬ë§·

    Args:
        result: PM ì‹¤í–‰ ê²°ê³¼
        selection: LLM ì„ íƒ ì •ë³´
        suggestions: ìœ ì‚¬ ì¼€ì´ìŠ¤ ì œì•ˆ (ì„ íƒ)
    """
    lines = []

    # í—¤ë”
    status = "âœ… ì„±ê³µ" if result.success else "âŒ ì‹¤íŒ¨"
    lines.append(f"## PM ì‘ì—… ê²°ê³¼: {status}")
    lines.append("")

    # ë©”íƒ€ ì •ë³´
    lines.append(f"- **LLM**: {result.llm_used.upper()}")
    lines.append(f"- **ì„ íƒ ì´ìœ **: {selection.reason}")
    lines.append(f"- **í™•ì‹ ë„**: {selection.confidence:.0%}")
    lines.append(f"- **ì†Œìš” ì‹œê°„**: {result.duration:.1f}ì´ˆ")
    lines.append(f"- **í”„ë¡œì íŠ¸**: `{result.project_path}`")
    lines.append("")

    # ìœ ì‚¬ ì¼€ì´ìŠ¤ ì œì•ˆ (ìˆìœ¼ë©´)
    if suggestions:
        suggestion_text = format_suggestions_context(suggestions)
        if suggestion_text:
            lines.append(suggestion_text)
            lines.append("")

    # ì¶œë ¥
    if result.output:
        lines.append("### ì‹¤í–‰ ê²°ê³¼")
        lines.append("```")
        # ì¶œë ¥ì´ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
        output = result.output[:2000]
        if len(result.output) > 2000:
            output += "\n... (ì¶œë ¥ ìƒëµ)"
        lines.append(output)
        lines.append("```")

    # ì—ëŸ¬
    if result.error:
        lines.append("")
        lines.append("### âš ï¸ ì—ëŸ¬")
        lines.append(f"```\n{result.error[:500]}\n```")

    return "\n".join(lines)


def run_pm_task_with_suggestions(
    project: str,
    instruction: str,
    llm_override: Optional[str] = None,
    use_tmux: bool = True
) -> Tuple[PMResult, LLMSelection, list[SimilarSuggestion]]:
    """
    PM ì‘ì—… ì‹¤í–‰ + ìœ ì‚¬ ì¼€ì´ìŠ¤ ì œì•ˆ í¬í•¨

    Args:
        project: í”„ë¡œì íŠ¸ëª… ë˜ëŠ” ë³„ì¹­
        instruction: ì§€ì‹œ ë‚´ìš©
        llm_override: ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí•œ LLM (ìˆìœ¼ë©´ ìë™ ì„ íƒ ë¬´ì‹œ)
        use_tmux: Trueë©´ tmux ì„¸ì…˜ ì‚¬ìš©, Falseë©´ subprocess ì‚¬ìš©

    Returns:
        (PMResult, LLMSelection, list[SimilarSuggestion]) íŠœí”Œ
    """
    # 1. ìœ ì‚¬ ì¼€ì´ìŠ¤ ë¨¼ì € ê²€ìƒ‰
    suggestions = get_similar_suggestions(instruction, project=project, limit=3)

    # 2. ì‘ì—… ì‹¤í–‰
    result, selection = run_pm_task(project, instruction, llm_override, use_tmux)

    return result, selection, suggestions


# CLI í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 3:
        print("Usage: pm_executor.py <project> <instruction>")
        print("Example: pm_executor.py í•´ë™ê²€ë„ 'í…ŒìŠ¤íŠ¸ ì‹¤í–‰'")
        sys.exit(1)

    project = sys.argv[1]
    instruction = " ".join(sys.argv[2:])

    print(f"í”„ë¡œì íŠ¸: {project}")
    print(f"ì§€ì‹œ: {instruction}")
    print("-" * 40)

    # LLM ì„ íƒ ë¯¸ë¦¬ë³´ê¸°
    selection = select_llm(instruction)
    print(f"ì¶”ì²œ LLM: {selection.llm}")
    print(f"í™•ì‹ ë„: {selection.confidence:.0%}")
    print(f"ì´ìœ : {selection.reason}")
    print(f"í™•ì¸ í•„ìš”: {needs_confirmation(selection)}")
